{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: JutasiR\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data as web\n",
    "import datetime as dt\n",
    "\n",
    "def sp_components(savefolder,\n",
    "                  savename):\n",
    "\n",
    "    print(\"Downloading the component data of S&P500\")\n",
    "    tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    sp_500_data = tables[0]\n",
    "    sp_500_data.columns = [str(x).strip() for x in sp_500_data.columns]\n",
    "    sp_500_data.columns = sp_500_data.columns.str.replace(\"GICS Sector\", \"GICS_Sector\")\n",
    "    \n",
    "    (sp_500_data\n",
    "         .filter([\"Symbol\", \"Security\", \"GICS_Sector\"])\n",
    "         .to_excel(os.path.join(savefolder, savename),\n",
    "                   index = False,\n",
    "                   freeze_panes = (1, 1)))\n",
    "    \n",
    "    print(f\"S&P500 component table ({savename}) has been saved down\")\n",
    "    \n",
    "    return ['^GSPC'] + [str(x).strip() for x in sp_500_data[\"Symbol\"]]\n",
    "\n",
    "def save_data_from_web(nr_of_years,\n",
    "                       savefolder,\n",
    "                       savename_comp,\n",
    "                       savename_hist_data):\n",
    "\n",
    "    new_year = dt.date.today().year - nr_of_years\n",
    "    start_date = str(dt.date(new_year, dt.date.today().month, dt.date.today().day))\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    tickers = sp_components(savefolder, savename_comp)\n",
    "\n",
    "    print(\"Download of closing prices by ticker from the given date period from Yahoo...\")\n",
    "    for share in tickers:\n",
    "        try:\n",
    "            data[share] = web.DataReader(share, data_source = \"yahoo\", start = start_date)[\"Adj Close\"]\n",
    "\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            try:\n",
    "                data[share] = web.DataReader(share, data_source = \"yahoo\", start = start_date)[\"Adj Close\"]\n",
    "            except:\n",
    "                print(\" - {0} cannot be loaded\".format(share))\n",
    "                continue\n",
    "    \n",
    "    data.index = [dt.date(date.year, date.month, date.day) for date in data.index]\n",
    "    data.index.name = \"Date\"\n",
    "    \n",
    "    (data\n",
    "        .fillna(method = 'ffill', axis = 'index')\n",
    "        .dropna(how = 'any', axis = 'columns')\n",
    "        .to_excel(os.path.join(savefolder, savename_hist_data),\n",
    "                  index = True,\n",
    "                  freeze_panes = (1, 1)))\n",
    "    \n",
    "    print(f\"\\nTime series ({savename_hist_data}) has been saved down\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
